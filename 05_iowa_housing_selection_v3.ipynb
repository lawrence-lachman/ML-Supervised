{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from scipy.stats import skew\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png' #set 'png' here when working on notebook\n",
    "\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/iowa-housing/train.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
       "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
       "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
       "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
       "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
       "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
       "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
       "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
       "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
       "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
       "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
       "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
       "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
       "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
       "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
       "       'SaleCondition', 'SalePrice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all categorical data\n",
    "cats = [col for col in df.columns.values if df[col].dtype == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 38)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create separate datasets for continuous and categorical data\n",
    "df_cont = df.drop(cats, axis=1)\n",
    "df_cats = df[cats]\n",
    "df_cont.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    804\n",
       "2    358\n",
       "4    213\n",
       "1     50\n",
       "5     21\n",
       "6      7\n",
       "0      6\n",
       "8      1\n",
       "Name: BedroomAbvGr, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cont.BedroomAbvGr.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cont.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                 0\n",
       "MSSubClass         0\n",
       "LotFrontage      259\n",
       "LotArea            0\n",
       "OverallQual        0\n",
       "OverallCond        0\n",
       "YearBuilt          0\n",
       "YearRemodAdd       0\n",
       "MasVnrArea         8\n",
       "BsmtFinSF1         0\n",
       "BsmtFinSF2         0\n",
       "BsmtUnfSF          0\n",
       "TotalBsmtSF        0\n",
       "1stFlrSF           0\n",
       "2ndFlrSF           0\n",
       "LowQualFinSF       0\n",
       "GrLivArea          0\n",
       "BsmtFullBath       0\n",
       "BsmtHalfBath       0\n",
       "FullBath           0\n",
       "HalfBath           0\n",
       "BedroomAbvGr       0\n",
       "KitchenAbvGr       0\n",
       "TotRmsAbvGrd       0\n",
       "Fireplaces         0\n",
       "GarageYrBlt       81\n",
       "GarageCars         0\n",
       "GarageArea         0\n",
       "WoodDeckSF         0\n",
       "OpenPorchSF        0\n",
       "EnclosedPorch      0\n",
       "3SsnPorch          0\n",
       "ScreenPorch        0\n",
       "PoolArea           0\n",
       "MiscVal            0\n",
       "MoSold             0\n",
       "YrSold             0\n",
       "SalePrice          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cont.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total square footage of each house\n",
    "df_cont['TotalSF'] = df_cont['1stFlrSF'] + df_cont['2ndFlrSF'] + df_cont['TotalBsmtSF']\n",
    "# y = df_cont.SalePrice\n",
    "y = np.log(df_cont.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "def executeModelCV(model, X):\n",
    "    # Negate the scores since neg_mean_squared_error returns negative scores, take the mean of the 10 scores, and \n",
    "    # since it is squared, take the square root\n",
    "    \n",
    "    # cross_val_score override scoring function to compute inverse log\n",
    "    scores = np.sqrt(-cross_val_score(model, X, y, cv = 10, scoring = 'neg_mean_squared_error').mean())\n",
    "    return(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26387383469757764"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "feature_cols = ['1stFlrSF', '2ndFlrSF', 'BedroomAbvGr']\n",
    "executeModelCV(LinearRegression(), df_cont[feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't use 'YearBuilt' because in a time value problem, newer houses typically sell for more money\n",
    "feature_cols = ['TotalSF', 'FullBath', 'OverallQual', 'OverallCond', 'TotRmsAbvGrd', 'LotArea']\n",
    "executeModelCV(LinearRegression(), df_cont[feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "max_depth_range = range(1, 8)\n",
    "RMSE_scores = []    # list to store the average RMSE for each value of max_depth\n",
    "\n",
    "# For each depth, instantiate a DecisionTreeRegressor\n",
    "for depth in max_depth_range:\n",
    "    RMSE_scores.append(executeModelCV(DecisionTreeRegressor(max_depth = depth, random_state = 1), df_cont[feature_cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot max_depth (x-axis) versus RMSE (y-axis)\n",
    "md = max_depth_range\n",
    "plt.plot(max_depth_range, RMSE_scores)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('RMSE (lower is better)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['TotalSF', 'FullBath', 'OverallQual', 'OverallCond', 'TotRmsAbvGrd', 'LotArea']\n",
    "\n",
    "treereg = DecisionTreeRegressor(max_depth = 6, random_state = 1)\n",
    "# The DecisionTreeRegressor instance must be fitted to be able to call treereg.feature_importances_\n",
    "treereg.fit(df_cont[feature_cols], y)\n",
    "executeModelCV(treereg, df_cont[feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Gini importance\" of each feature: the (normalized) total reduction of error \n",
    "# brought by that feature\n",
    "newdf = pd.DataFrame({'feature':feature_cols, 'importance':treereg.feature_importances_})\n",
    "newdf.sort_values('importance', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove LotFrontage and 'MasVnrArea' because of NaN values\n",
    "feature_cols = ['OverallQual', 'GrLivArea', 'BedroomAbvGr', 'GarageCars', 'MSSubClass', 'YearBuilt', 'TotRmsAbvGrd', \n",
    "                'BsmtFullBath', 'KitchenAbvGr', 'YearRemodAdd', 'OverallCond', 'Fireplaces', 'TotalSF',\n",
    "                'MoSold', 'ScreenPorch', 'LotArea']\n",
    "\n",
    "treereg = DecisionTreeRegressor(max_depth = 6, random_state = 1)\n",
    "# The DecisionTreeRegressor instance must be fitted to be able to call treereg.feature_importances_\n",
    "treereg.fit(df_cont[feature_cols], y)\n",
    "executeModelCV(treereg, df_cont[feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Gini importance\" of each feature: the (normalized) total reduction of error \n",
    "# brought by that feature\n",
    "newdf = pd.DataFrame({'feature':feature_cols, 'importance':treereg.feature_importances_})\n",
    "newdf.sort_values('importance', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a GraphViz file\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# Easier to read the .svg file in a browser than a .png file\n",
    "export_graphviz(treereg, out_file = 'iowa_house-decision-tree.dot', feature_names = feature_cols)\n",
    "! dot -Tsvg iowa_house-decision-tree.dot -o iowa_house-decision-tree.svg\n",
    "! dot -Tpng iowa_house-decision-tree.dot -o iowa_house-decision-tree.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "maxEstimatorRange = range(3, 16)\n",
    "RMSE_scores = []    # list to store the average RMSE for each value of max_depth\n",
    "\n",
    "# For each number of estimators, instantiate a DecisionTreeRegressor\n",
    "for numEst in maxEstimatorRange:\n",
    "    RMSE_scores.append(executeModelCV(RandomForestRegressor(max_depth = 6, n_estimators = numEst, max_features = 1), \n",
    "                                                            df_cont[feature_cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot max_estimators (x-axis) versus RMSE (y-axis)\n",
    "plt.plot(maxEstimatorRange, RMSE_scores)\n",
    "plt.xlabel('max_estimators')\n",
    "plt.ylabel('RMSE (lower is better)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "names = [\"Linear Regression\", \"Decision Tree\", \"Nearest Neighbors\", \"Random Forest\", \"AdaBoost\"]\n",
    "\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    DecisionTreeRegressor(max_depth = 6, random_state = 1),\n",
    "    KNeighborsRegressor(n_neighbors = 6),\n",
    "    RandomForestRegressor(max_depth = 6, n_estimators = 12, max_features = 1),\n",
    "    AdaBoostRegressor()]\n",
    "\n",
    "# iterate over classifiers\n",
    "for modelName, model in zip(names, models):\n",
    "    print(modelName, executeModelCV(model, df_cont[feature_cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# All Features except 'GarageYrBlt' and 'MasVnrArea' because of NaN values\n",
    "feature_cols = ['TotalSF', '3SsnPorch', 'BedroomAbvGr', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtFullBath', 'BsmtHalfBath', \n",
    "                'BsmtUnfSF', 'EnclosedPorch', 'Fireplaces', 'FullBath', 'GarageArea', 'GarageCars', \n",
    "                'GrLivArea', 'HalfBath', 'Id', 'KitchenAbvGr', 'LotArea', 'LowQualFinSF', 'MSSubClass', \n",
    "                'MiscVal', 'MoSold', 'OpenPorchSF', 'OverallCond', 'OverallQual', 'PoolArea', 'ScreenPorch', \n",
    "                'TotRmsAbvGrd', 'WoodDeckSF', 'YearBuilt', 'YearRemodAdd', 'YrSold']\n",
    "\n",
    "X = df_cont[feature_cols]\n",
    "y = df_cont.SalePrice\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_test)\n",
    "np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coef_ variable doesn't exist until the fit() method is invoked\n",
    "linreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Feature\": feature_cols, \"coef\":linreg.coef_})\n",
    "df['coefmagnitude'] = df.coef.map(lambda x: abs(x))\n",
    "df.sort_values('coefmagnitude', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(linreg, random_state = 1).fit(X_test, y_test)\n",
    "eli5.show_weights(perm, feature_names = X_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on output from model itself  (feature importance)\n",
    "feature_cols = ['KitchenAbvGr', 'GarageCars', 'OverallQual', 'BsmtFullBath', 'BedroomAbvGr', 'Fireplaces', 'OverallCond', \n",
    "                'TotRmsAbvGrd', 'FullBath', 'YearBuilt', 'MoSold', 'MSSubClass', 'YearRemodAdd', 'PoolArea', 'TotalSF', \n",
    "                'LotArea']\n",
    "X = df_cont[feature_cols]\n",
    "y = df_cont['SalePrice']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_test)\n",
    "np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on output from model itself, but this time, remove features with a negative coefficient:  'KitchenAbvGr', \n",
    "# 'BedroomAbvGr', 'YrSold', 'HalfBath', 'MoSold', 'MSSubClass', 'PoolArea', 'BsmtFinSF2', 'Id', 'BsmtUnfSF', 'MiscVal'\n",
    "feature_cols = ['OverallQual', 'GarageCars', 'BsmtFullBath', 'TotRmsAbvGrd', 'BsmtHalfBath', 'FullBath', 'Fireplaces', \n",
    "                'OverallCond', 'YearBuilt', 'YearRemodAdd', 'ScreenPorch', 'WoodDeckSF', 'EnclosedPorch', 'GrLivArea', \n",
    "                'TotalSF', '3SsnPorch', 'LowQualFinSF', 'BsmtFinSF1', 'OpenPorchSF', 'GarageArea', 'LotArea']\n",
    "X = df_cont[feature_cols]\n",
    "y = df_cont.SalePrice\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_test)\n",
    "np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on output from eli (feature importance)\n",
    "feature_cols = ['OverallQual', 'GrLivArea', 'TotalSF', 'TotRmsAbvGrd', 'YearBuilt', 'GarageCars', 'BedroomAbvGr', 'BsmtFinSF1', \n",
    "                'MSSubClass', 'BsmtFullBath', 'LotArea', 'Fireplaces', 'WoodDeckSF', 'FullBath', 'KitchenAbvGr', 'YearRemodAdd', \n",
    "                'OverallCond', 'ScreenPorch', 'GarageArea', 'BsmtFinSF2']\n",
    "X = df_cont[feature_cols]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_test)\n",
    "np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing using zero mean and unit variance scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Rescale data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train_scaled, y_train)\n",
    "y_pred = linreg.predict(X_test_scaled)\n",
    "np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['OverallQual', 'GarageCars', 'BsmtFullBath', 'TotRmsAbvGrd', 'BsmtHalfBath', 'FullBath', 'Fireplaces', \n",
    "                'OverallCond', 'YearBuilt', 'YearRemodAdd', 'ScreenPorch', 'WoodDeckSF', 'EnclosedPorch', 'GrLivArea', \n",
    "                'TotalSF', '3SsnPorch', 'LowQualFinSF', 'BsmtFinSF1', 'OpenPorchSF', 'GarageArea', 'LotArea']\n",
    "\n",
    "# Iterate over classifiers using new feature list\n",
    "for modelName, model in zip(names, models):\n",
    "    print(modelName, executeModelCV(model, df_cont[feature_cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['OverallQual', 'GrLivArea', 'TotalSF', 'TotRmsAbvGrd', 'YearBuilt', 'GarageCars', 'BedroomAbvGr', 'BsmtFinSF1', \n",
    "                'MSSubClass', 'BsmtFullBath', 'LotArea', 'Fireplaces', 'WoodDeckSF', 'FullBath', 'KitchenAbvGr', 'YearRemodAdd', \n",
    "                'OverallCond', 'ScreenPorch', 'GarageArea', 'BsmtFinSF2']\n",
    "\n",
    "for modelName, model in zip(names, models):\n",
    "    print(modelName, executeModelCV(model, df_cont[feature_cols]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now work on the Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cats.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cats.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plots of categorical features\n",
    "for feature in df_cats.dtypes.index:\n",
    "    sns.countplot(y = feature, data = df_cats, order = df_cats[feature].value_counts().index)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Assign all of the features to feature_cols, except those with over 5000 NaNs, which will be dropped:  \n",
    "# 'Alley', 'FireplaceQu', 'PoolQC', 'Fence', and 'MiscFeature'.  \n",
    "feature_cols = ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', \n",
    "                'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', \n",
    "                'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', \n",
    "                'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'GarageType', \n",
    "                'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'SaleType', 'SaleCondition']\n",
    "\n",
    "df_cats = df_cats[feature_cols]\n",
    "\n",
    "# The rest of the features with NaNs are all below 100.  We want to maintain the same number of rows (1,460) so that we can \n",
    "# successfully perform an outer join with df_cont, so use the SimpleImputer to impute the missing values, using the most \n",
    "# frequent strategy\n",
    "imp = SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')\n",
    "df_cats_imputed = pd.DataFrame(imp.fit_transform(df_cats))\n",
    "df_cats_imputed.columns = df_cats.columns\n",
    "df_cats_imputed.index = df_cats.index\n",
    "\n",
    "df_cats_imputed.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original code used to develop encodeCategoricalData()\n",
    "'''\n",
    "MSZoning = df_cats_imputed.MSZoning.value_counts()\n",
    "count = MSZoning.count()\n",
    "MSZoning\n",
    "\n",
    "mapping = {}\n",
    "i = 0\n",
    "j = MSZoning.count() - 1\n",
    "# Create a dictionary of key:value value pairs where the value count of the most frequent has the highest encoded value\n",
    "# featureCount - 1\n",
    "for feature in MSZoning:\n",
    "    mapping.update({MSZoning.index[i]:j})\n",
    "    i += 1\n",
    "    j -= 1\n",
    "    \n",
    "mapping\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the categorical data as numerical values based on value counts, where the most frequent feature values have the \n",
    "# largest encoded value such that machine learning algorithms interpret a feature category encoded to 8 to be given 8x more \n",
    "# weight than a category within the same feature encoded to 1\n",
    "def encodeCategoricalDataByValueCounts(feature):\n",
    "    featureValueCounts = df_cats_imputed[feature].value_counts()    \n",
    "    mapping = {}\n",
    "    i = 0\n",
    "    j = featureValueCounts.count() - 1\n",
    "    # Build a dictionary of key:value value pairs where the value count of the most frequent has the highest encoded value:\n",
    "    # featureValueCounts.count() - 1\n",
    "    for value in featureValueCounts:\n",
    "        mapping.update({featureValueCounts.index[i]:j})\n",
    "        i += 1\n",
    "        j -= 1\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cats_imputed.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in df_cats_imputed.dtypes.index:\n",
    "    mapping = encodeCategoricalDataByValueCounts(feature)\n",
    "    df_cats_imputed[feature] = df_cats_imputed[feature].map(mapping)\n",
    "\n",
    "df_cats_imputed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_range = range(1, 8)\n",
    "RMSE_scores = []    # list to store the average RMSE for each value of max_depth\n",
    "\n",
    "# For each depth, instantiate a DecisionTreeRegressor\n",
    "for depth in max_depth_range:\n",
    "    RMSE_scores.append(executeModelCV(DecisionTreeRegressor(max_depth = depth, random_state = 1), df_cats_imputed[feature_cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot max_depth (x-axis) versus RMSE (y-axis)\n",
    "md = max_depth_range\n",
    "plt.plot(max_depth_range, RMSE_scores)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('RMSE (lower is better)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treereg = DecisionTreeRegressor(max_depth = 6, random_state = 1)\n",
    "# The DecisionTreeRegressor instance must be fitted to be able to call treereg.feature_importances_\n",
    "treereg.fit(df_cats_imputed[feature_cols], y)\n",
    "executeModelCV(treereg, df_cats_imputed[feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Gini importance\" of each feature: the (normalized) total reduction of error \n",
    "# brought by that feature\n",
    "newdf = pd.DataFrame({'feature':feature_cols, 'importance':treereg.feature_importances_})\n",
    "newdf.sort_values('importance', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on output from model itself, with values over 0.018\n",
    "feature_cols = ['ExterQual', 'BsmtQual', 'Neighborhood', 'GarageFinish', 'KitchenQual', 'BsmtExposure', 'RoofMatl', 'BldgType',\n",
    "                'SaleCondition']\n",
    "# Results:\n",
    "# Linear Regression 55570.426480754395\n",
    "# Decision Tree 51178.67443758195\n",
    "# Nearest Neighbors 48393.65693873129\n",
    "# Random Forest 48739.97880164021\n",
    "# AdaBoost 54129.10737023764\n",
    "\n",
    "feature_cols = ['ExterQual', 'BsmtQual', 'Neighborhood', 'GarageFinish', 'KitchenQual', 'BsmtExposure', 'MSZoning', 'ExterQual',\n",
    "               'CentralAir']\n",
    "# Results\n",
    "# Linear Regression 54290.36003260593\n",
    "# Decision Tree 49684.99993616181\n",
    "# Nearest Neighbors 48379.85671631011\n",
    "# Random Forest 47040.59819859272\n",
    "# AdaBoost 55463.76504232442\n",
    "\n",
    "# iterate over classifiers using new feature list\n",
    "for modelName, model in zip(names, models):\n",
    "    print(modelName, executeModelCV(model, df_cats_imputed[feature_cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cats_imputed[feature_cols]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_test)\n",
    "np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coef_ variable doesn't exist until the fit() method is invoked\n",
    "linreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Feature\": feature_cols, \"coef\":linreg.coef_})\n",
    "df['coefmagnitude'] = df.coef.map(lambda x: abs(x))\n",
    "df.sort_values('coefmagnitude', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = PermutationImportance(linreg, random_state = 1).fit(X_test, y_test)\n",
    "eli5.show_weights(perm, feature_names = X_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on output from model itself, but remove features with a negative coefficient:  'ExterQual', 'KitchenQual', 'GarageQual', \n",
    "# 'BsmtQual', 'LandSlope', 'RoofStyle', 'MasVnrType', 'GarageFinish', 'BsmtExposure', 'LotShape', 'Heating', 'SaleType', \n",
    "# 'RoofMatl', 'Exterior1st', 'HouseStyle', 'GarageType', 'BsmtFinType2', 'Neighborhood', 'BsmtFinType1', \n",
    "feature_cols = ['Street', 'Utilities', 'CentralAir', 'GarageCond', 'BldgType', 'PavedDrive', 'Electrical', 'MSZoning', \n",
    "                'Functional', 'LandContour', 'Foundation', 'HeatingQC', 'Condition2', 'ExterCond', 'SaleCondition', 'BsmtCond', \n",
    "                'Condition1', 'Exterior2nd', 'LotConfig']\n",
    "# Results:\n",
    "# Linear Regression 66955.98763433268\n",
    "# Decision Tree 65237.218708631925\n",
    "# Nearest Neighbors 66935.53467424955\n",
    "# Random Forest 66180.04137507977\n",
    "# AdaBoost 70924.95613788051\n",
    "\n",
    "feature_cols = ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', \n",
    "                'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', \n",
    "                'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', \n",
    "                'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'GarageType', \n",
    "                'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'SaleType', 'SaleCondition']\n",
    "# Results:\n",
    "# Linear Regression 51750.23690084067\n",
    "# Decision Tree 55737.72912119848\n",
    "# Nearest Neighbors 51738.37060932254\n",
    "# Random Forest 57250.380129610916\n",
    "# AdaBoost 52913.70551792658\n",
    "\n",
    "# iterate over classifiers using new feature list\n",
    "for modelName, model in zip(names, models):\n",
    "    print(modelName, executeModelCV(model, df_cats_imputed[feature_cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cont.shape)\n",
    "print(df_cats_imputed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_cont, df_cats_imputed], axis = 1, join_axes = [df_cont.index], join = 'outer')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [# df_cont features\n",
    "    'OverallQual', 'GrLivArea', 'TotalSF', 'TotRmsAbvGrd', 'YearBuilt', 'GarageCars', 'BedroomAbvGr', 'BsmtFinSF1', \n",
    "    'MSSubClass', 'BsmtFullBath', 'LotArea', 'Fireplaces', 'WoodDeckSF', 'FullBath', 'KitchenAbvGr', 'YearRemodAdd', \n",
    "    'OverallCond', 'ScreenPorch', 'GarageArea', 'BsmtFinSF2',\n",
    "    # df_cats_imputed features\n",
    "    'ExterQual', 'BsmtQual', 'Neighborhood', 'GarageFinish', 'KitchenQual', 'BsmtExposure', 'MSZoning', 'ExterQual', \n",
    "    'CentralAir']\n",
    "\n",
    "# iterate over classifiers using new feature list\n",
    "for modelName, model in zip(names, models):\n",
    "    print(modelName, executeModelCV(model, df[feature_cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
